{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1430b7e",
   "metadata": {},
   "source": [
    "# AWS Bedrock\n",
    "## Text Generation\n",
    "\n",
    "In this notebook, we will explore the use of the AWS Bedrock Converse API, an interface that allows conversational interaction with foundational language models (FLMs) hosted on the Amazon Bedrock service.\n",
    "\n",
    "The goal is to demonstrate how to establish a connection with Bedrock, send messages or prompts to the model, and process responses within a conversational flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e61cd3-a637-47cc-bb92-920c5c5956b7",
   "metadata": {},
   "source": [
    "# 1- Text Generation\n",
    "\n",
    "Learn the basics of the Amazon Bedrock Invoke API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "087c8f54-0905-45fd-a8ca-86a8ffb04871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:08:42.366003Z",
     "iopub.status.busy": "2025-10-15T18:08:42.365559Z",
     "iopub.status.idle": "2025-10-15T18:08:42.653764Z",
     "shell.execute_reply": "2025-10-15T18:08:42.653033Z",
     "shell.execute_reply.started": "2025-10-15T18:08:42.365955Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "from IPython.display import display, Markdown\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a638ded-36a9-4ddc-96df-49e9184b6353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:10:14.404413Z",
     "iopub.status.busy": "2025-10-15T18:10:14.404125Z",
     "iopub.status.idle": "2025-10-15T18:10:14.418434Z",
     "shell.execute_reply": "2025-10-15T18:10:14.417823Z",
     "shell.execute_reply.started": "2025-10-15T18:10:14.404389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init Bedrock client\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock = boto3.client(service_name='bedrock-runtime', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02ef0a54-7ff3-4c76-a232-ce707e1811be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:25:39.213869Z",
     "iopub.status.busy": "2025-10-15T18:25:39.213594Z",
     "iopub.status.idle": "2025-10-15T18:25:39.216671Z",
     "shell.execute_reply": "2025-10-15T18:25:39.216184Z",
     "shell.execute_reply.started": "2025-10-15T18:25:39.213847Z"
    }
   },
   "outputs": [],
   "source": [
    "model_sonnet_id = \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faca3e1c-75d6-43fd-b05c-7734aff47258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:12:15.510680Z",
     "iopub.status.busy": "2025-10-15T18:12:15.510391Z",
     "iopub.status.idle": "2025-10-15T18:12:15.513613Z",
     "shell.execute_reply": "2025-10-15T18:12:15.512840Z",
     "shell.execute_reply.started": "2025-10-15T18:12:15.510659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create prompt \n",
    "city = \"Valencia\"\n",
    "\n",
    "prompt = f\"\"\"Create a three-day itinerary to explore the city. The city is: \n",
    "<text>\n",
    "{city}\n",
    "</text>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c2dd9-5bd1-41a0-8b81-b7d96b9f35d0",
   "metadata": {},
   "source": [
    "## Invoke Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1673412a-ca48-427e-a4ad-e0dc0c253ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:12:34.733420Z",
     "iopub.status.busy": "2025-10-15T18:12:34.733155Z",
     "iopub.status.idle": "2025-10-15T18:12:34.736984Z",
     "shell.execute_reply": "2025-10-15T18:12:34.736295Z",
     "shell.execute_reply.started": "2025-10-15T18:12:34.733399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create request body for Claude 3.7 Sonnet\n",
    "claude_body = json.dumps({\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 1000,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.9,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}]\n",
    "        }\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2a7bf4-32ea-47d2-bf0b-bb75251563a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:13:42.406359Z",
     "iopub.status.busy": "2025-10-15T18:13:42.406108Z",
     "iopub.status.idle": "2025-10-15T18:14:00.105227Z",
     "shell.execute_reply": "2025-10-15T18:14:00.104583Z",
     "shell.execute_reply.started": "2025-10-15T18:13:42.406338Z"
    }
   },
   "outputs": [],
   "source": [
    "response = bedrock.invoke_model(\n",
    "        modelId=model_sonnet_id,\n",
    "        body=claude_body,\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8206d94-db0a-4ed0-be8b-0914b70c5971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:14:18.115649Z",
     "iopub.status.busy": "2025-10-15T18:14:18.115379Z",
     "iopub.status.idle": "2025-10-15T18:14:18.121902Z",
     "shell.execute_reply": "2025-10-15T18:14:18.121126Z",
     "shell.execute_reply.started": "2025-10-15T18:14:18.115628Z"
    }
   },
   "outputs": [],
   "source": [
    "response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4e39b-340a-43cf-a8b5-4700155ea911",
   "metadata": {},
   "source": [
    "Although the Invoke Model API allows direct access to base models, it has several limitations:\n",
    "\n",
    "- It uses different request/response formats for each model family.\n",
    "\n",
    "- It does not offer built-in support for multi-turn conversations.\n",
    "\n",
    "- It requires custom handling based on the capabilities of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0054893e-4788-4bf0-85b2-4975b584190a",
   "metadata": {},
   "source": [
    "## Converse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3b7678-5d89-4dee-9014-e1aa85db2cd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:18:01.077158Z",
     "iopub.status.busy": "2025-10-15T18:18:01.076774Z",
     "iopub.status.idle": "2025-10-15T18:18:01.083630Z",
     "shell.execute_reply": "2025-10-15T18:18:01.082791Z",
     "shell.execute_reply.started": "2025-10-15T18:18:01.077126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a converse request \n",
    "converse_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\n",
    "        \"temperature\": 0.4,\n",
    "        \"topP\": 0.9,\n",
    "        \"maxTokens\": 500\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300c8e16-fcf4-4c9b-a422-df51abbd2a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:18:06.311012Z",
     "iopub.status.busy": "2025-10-15T18:18:06.310730Z",
     "iopub.status.idle": "2025-10-15T18:18:16.986739Z",
     "shell.execute_reply": "2025-10-15T18:18:16.985967Z",
     "shell.execute_reply.started": "2025-10-15T18:18:06.310987Z"
    }
   },
   "outputs": [],
   "source": [
    "response = bedrock.converse(\n",
    "        modelId=model_sonnet_id,\n",
    "        messages=converse_request[\"messages\"],\n",
    "        inferenceConfig=converse_request[\"inferenceConfig\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2c26d-aac5-4c32-9ae0-4a37c8bddb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:18:27.581613Z",
     "iopub.status.busy": "2025-10-15T18:18:27.581328Z",
     "iopub.status.idle": "2025-10-15T18:18:27.586643Z",
     "shell.execute_reply": "2025-10-15T18:18:27.585862Z",
     "shell.execute_reply.started": "2025-10-15T18:18:27.581588Z"
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398b68a-a592-46e7-a61a-c5bf428fa292",
   "metadata": {},
   "source": [
    "The Converse API facilitates multi-turn conversations. We can extract the response directly and simulate the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a582776-f9f7-46bf-b24b-e7d61a37435c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:21:10.609440Z",
     "iopub.status.busy": "2025-10-15T18:21:10.609177Z",
     "iopub.status.idle": "2025-10-15T18:21:10.612360Z",
     "shell.execute_reply": "2025-10-15T18:21:10.611707Z",
     "shell.execute_reply.started": "2025-10-15T18:21:10.609418Z"
    }
   },
   "outputs": [],
   "source": [
    "model_response = response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee39d2-81da-4d67-b506-c56fa3304cbd",
   "metadata": {},
   "source": [
    "## Multi-Turn conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e14bfdb8-80a3-4493-8441-5bf1274eccb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:22:48.819159Z",
     "iopub.status.busy": "2025-10-15T18:22:48.818898Z",
     "iopub.status.idle": "2025-10-15T18:22:48.822347Z",
     "shell.execute_reply": "2025-10-15T18:22:48.821818Z",
     "shell.execute_reply.started": "2025-10-15T18:22:48.819139Z"
    }
   },
   "outputs": [],
   "source": [
    "# create conversation\n",
    "multi_turn_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": prompt}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"text\": model_response}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Only a two-day trip.\"}]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b0d8dc-d799-4bcf-bd51-397f16d684f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:22:49.391622Z",
     "iopub.status.busy": "2025-10-15T18:22:49.391350Z",
     "iopub.status.idle": "2025-10-15T18:22:56.304031Z",
     "shell.execute_reply": "2025-10-15T18:22:56.302794Z",
     "shell.execute_reply.started": "2025-10-15T18:22:49.391599Z"
    }
   },
   "outputs": [],
   "source": [
    "response = bedrock.converse(\n",
    "        modelId=model_sonnet_id,\n",
    "        messages=multi_turn_messages,\n",
    "        inferenceConfig={\"temperature\": 0.2, \"maxTokens\": 500}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c21f36-e381-4794-934a-4475aad57366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:23:01.105300Z",
     "iopub.status.busy": "2025-10-15T18:23:01.104990Z",
     "iopub.status.idle": "2025-10-15T18:23:01.110470Z",
     "shell.execute_reply": "2025-10-15T18:23:01.109655Z",
     "shell.execute_reply.started": "2025-10-15T18:23:01.105266Z"
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e77285-fa56-483a-912f-9f0c32671c76",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Both InvokeModel and Converse allow streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee75e0c-9643-48a9-bb50-eac86ab72b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:24:01.115291Z",
     "iopub.status.busy": "2025-10-15T18:24:01.115010Z",
     "iopub.status.idle": "2025-10-15T18:24:01.121648Z",
     "shell.execute_reply": "2025-10-15T18:24:01.120776Z",
     "shell.execute_reply.started": "2025-10-15T18:24:01.115268Z"
    }
   },
   "outputs": [],
   "source": [
    "def stream_converse(model_id, messages, inference_config=None):\n",
    "    if inference_config is None:\n",
    "        inference_config = {}\n",
    "    \n",
    "    print(\"Streaming response (chunks will appear as they are received):\\n\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    full_response = \"\"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.converse_stream(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            inferenceConfig=inference_config\n",
    "        )\n",
    "        response_stream = response.get('stream')\n",
    "        if response_stream:\n",
    "            for event in response_stream:\n",
    "\n",
    "                if 'messageStart' in event:\n",
    "                    print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "                if 'contentBlockDelta' in event:\n",
    "                    print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "\n",
    "                if 'messageStop' in event:\n",
    "                    print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "                if 'metadata' in event:\n",
    "                    metadata = event['metadata']\n",
    "                    if 'usage' in metadata:\n",
    "                        print(\"\\nToken usage\")\n",
    "                        print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "                        print(\n",
    "                            f\":Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "                        print(f\":Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "                    if 'metrics' in event['metadata']:\n",
    "                        print(\n",
    "                            f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "\n",
    "                \n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "        return full_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in streaming: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a768f76b-adda-4e02-961b-32736dde993a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:24:17.233296Z",
     "iopub.status.busy": "2025-10-15T18:24:17.233016Z",
     "iopub.status.idle": "2025-10-15T18:24:17.236661Z",
     "shell.execute_reply": "2025-10-15T18:24:17.236043Z",
     "shell.execute_reply.started": "2025-10-15T18:24:17.233273Z"
    }
   },
   "outputs": [],
   "source": [
    "streaming_request = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50894f-cee9-4918-b2d9-d25692e649b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:24:25.907796Z",
     "iopub.status.busy": "2025-10-15T18:24:25.907527Z",
     "iopub.status.idle": "2025-10-15T18:24:39.949246Z",
     "shell.execute_reply": "2025-10-15T18:24:39.948578Z",
     "shell.execute_reply.started": "2025-10-15T18:24:25.907774Z"
    }
   },
   "outputs": [],
   "source": [
    "streamed_response = stream_converse(\n",
    "    model_sonnet_id, \n",
    "    streaming_request, \n",
    "    inference_config={\"temperature\": 0.4, \"maxTokens\": 1000}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f50a1c-4069-43c4-a921-ebb40303d82a",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "\n",
    "Podemos configurar un LLM para llamar a una función o tool en su conversación. Esto se realiza a través de *toolConfig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f54fd86d-e138-465f-aea3-5cbe1e04661f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:28:14.317547Z",
     "iopub.status.busy": "2025-10-15T18:28:14.317217Z",
     "iopub.status.idle": "2025-10-15T18:28:14.321341Z",
     "shell.execute_reply": "2025-10-15T18:28:14.320799Z",
     "shell.execute_reply.started": "2025-10-15T18:28:14.317468Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    \"\"\"Mock function that would normally call a weather API\"\"\"\n",
    "    print(f\"Looking up weather for {location}...\")\n",
    "  \n",
    "    # In a real application, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"New York\": {\"condition\": \"Partly Cloudy\", \"temperature\": 72, \"humidity\": 65},\n",
    "        \"San Francisco\": {\"condition\": \"Foggy\", \"temperature\": 58, \"humidity\": 80},\n",
    "        \"Miami\": {\"condition\": \"Sunny\", \"temperature\": 85, \"humidity\": 75},\n",
    "        \"Seattle\": {\"condition\": \"Rainy\", \"temperature\": 52, \"humidity\": 90}\n",
    "    }\n",
    "  \n",
    "    return weather_data.get(location, {\"condition\": \"Unknown\", \"temperature\": 0, \"humidity\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36bd4f51-1df7-4883-8b42-773a8b4c2d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:28:41.456918Z",
     "iopub.status.busy": "2025-10-15T18:28:41.456653Z",
     "iopub.status.idle": "2025-10-15T18:28:41.460592Z",
     "shell.execute_reply": "2025-10-15T18:28:41.460010Z",
     "shell.execute_reply.started": "2025-10-15T18:28:41.456896Z"
    }
   },
   "outputs": [],
   "source": [
    "# define our tool\n",
    "\n",
    "weather_tool = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get current weather for a specific location\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city name to get weather for\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"location\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"toolChoice\": {\n",
    "        \"auto\": {}  # Let the model decide when to use the tool\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aec412e8-f4ad-4c0d-8d00-9cf917b761e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:28:56.285438Z",
     "iopub.status.busy": "2025-10-15T18:28:56.285175Z",
     "iopub.status.idle": "2025-10-15T18:28:56.288684Z",
     "shell.execute_reply": "2025-10-15T18:28:56.288102Z",
     "shell.execute_reply.started": "2025-10-15T18:28:56.285417Z"
    }
   },
   "outputs": [],
   "source": [
    "# model request\n",
    "\n",
    "function_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"What's the weather like in San Francisco right now? And what should I wear?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\n",
    "        \"temperature\": 0.0,  # Use 0 temperature for deterministic function calling\n",
    "        \"maxTokens\": 500\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9142e-e797-464d-b6bb-fb7f3ea4f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.converse(\n",
    "    modelId=MODELS[\"Claude 3.7 Sonnet\"],\n",
    "    messages=function_request[\"messages\"],\n",
    "    inferenceConfig=function_request[\"inferenceConfig\"],\n",
    "    toolConfig=weather_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83b9c9-976f-416f-ab0f-85182e41838a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:32:20.986819Z",
     "iopub.status.busy": "2025-10-15T18:32:20.986555Z",
     "iopub.status.idle": "2025-10-15T18:32:20.992703Z",
     "shell.execute_reply": "2025-10-15T18:32:20.991864Z",
     "shell.execute_reply.started": "2025-10-15T18:32:20.986798Z"
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1d66c-0216-43dc-a33c-b99149465ff3",
   "metadata": {},
   "source": [
    "We can see that it detects a toolUse. We could generate a function to execute this tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8987006-ab3b-48a7-9d0a-de0431f434b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:34:36.921900Z",
     "iopub.status.busy": "2025-10-15T18:34:36.921446Z",
     "iopub.status.idle": "2025-10-15T18:34:36.926774Z",
     "shell.execute_reply": "2025-10-15T18:34:36.926029Z",
     "shell.execute_reply.started": "2025-10-15T18:34:36.921866Z"
    }
   },
   "outputs": [],
   "source": [
    "content_blocks = response[\"output\"][\"message\"][\"content\"]\n",
    "has_tool_use = any(\"toolUse\" in block for block in content_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daf08634-3164-4db3-8720-401e4e031e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:35:45.843242Z",
     "iopub.status.busy": "2025-10-15T18:35:45.842976Z",
     "iopub.status.idle": "2025-10-15T18:35:45.847011Z",
     "shell.execute_reply": "2025-10-15T18:35:45.846471Z",
     "shell.execute_reply.started": "2025-10-15T18:35:45.843221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toolUseId': 'tooluse_bklY_OqiTAGfyEJlqmo6ew',\n",
       " 'name': 'get_weather',\n",
       " 'input': {'location': 'San Francisco'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_blocks[1]['toolUse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7cdd821-4f1c-4e7a-a110-48119888e630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:36:04.245956Z",
     "iopub.status.busy": "2025-10-15T18:36:04.245694Z",
     "iopub.status.idle": "2025-10-15T18:36:04.248752Z",
     "shell.execute_reply": "2025-10-15T18:36:04.248259Z",
     "shell.execute_reply.started": "2025-10-15T18:36:04.245935Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract needed data to execute\n",
    "if has_tool_use:\n",
    "    tool_use = content_blocks[1]['toolUse']\n",
    "    tool_name = tool_use[\"name\"]\n",
    "    tool_input = tool_use[\"input\"]\n",
    "    tool_use_id = tool_use[\"toolUseId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d8804f3-a8dc-4978-a0f3-ce6740a13a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:36:23.439331Z",
     "iopub.status.busy": "2025-10-15T18:36:23.439009Z",
     "iopub.status.idle": "2025-10-15T18:36:23.443585Z",
     "shell.execute_reply": "2025-10-15T18:36:23.442896Z",
     "shell.execute_reply.started": "2025-10-15T18:36:23.439303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up weather for San Francisco...\n"
     ]
    }
   ],
   "source": [
    "tool_output = get_weather(tool_input[\"location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d541f-3336-49c6-816e-055fcaea3fd7",
   "metadata": {},
   "source": [
    "Una vez tenemos la salida de la tool podemos pasarlo al llm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a577392-36ab-42ea-a80c-04089028c2fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:37:31.231771Z",
     "iopub.status.busy": "2025-10-15T18:37:31.231451Z",
     "iopub.status.idle": "2025-10-15T18:37:31.235400Z",
     "shell.execute_reply": "2025-10-15T18:37:31.234899Z",
     "shell.execute_reply.started": "2025-10-15T18:37:31.231749Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_messages = function_request[\"messages\"] + [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolUse\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"name\": tool_name,\n",
    "                                \"input\": tool_input\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [\n",
    "                                    {\n",
    "                                        \"json\": tool_output\n",
    "                                    }\n",
    "                                ],\n",
    "                                \"status\": \"success\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "076f1660-a0bd-4946-a5ab-6f844b45fd4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:38:18.843228Z",
     "iopub.status.busy": "2025-10-15T18:38:18.842967Z",
     "iopub.status.idle": "2025-10-15T18:38:22.715351Z",
     "shell.execute_reply": "2025-10-15T18:38:22.714699Z",
     "shell.execute_reply.started": "2025-10-15T18:38:18.843207Z"
    }
   },
   "outputs": [],
   "source": [
    "final_response = bedrock.converse(\n",
    "                modelId=model_sonnet_id,\n",
    "                messages=updated_messages,\n",
    "                inferenceConfig=function_request[\"inferenceConfig\"],\n",
    "                toolConfig=weather_tool  \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f56ff-9e9d-4a38-9d64-7c092cd07f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T18:38:24.808194Z",
     "iopub.status.busy": "2025-10-15T18:38:24.807929Z",
     "iopub.status.idle": "2025-10-15T18:38:24.813581Z",
     "shell.execute_reply": "2025-10-15T18:38:24.812750Z",
     "shell.execute_reply.started": "2025-10-15T18:38:24.808171Z"
    }
   },
   "outputs": [],
   "source": [
    "final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c24b6c-bf82-48c1-abe3-7cfa0ffb0e38",
   "metadata": {},
   "source": [
    "# Multimodal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bdf0e-9758-4a7f-9f0b-ec462319e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_conversation(bedrock_client,\n",
    "                          model_id,\n",
    "                          input_text,\n",
    "                          input_image):\n",
    "    \"\"\"\n",
    "    Sends a message to a model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        input text : The input message.\n",
    "        input_image : The input image.\n",
    "\n",
    "    Returns:\n",
    "        response (JSON): The conversation that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Generating message with model {model_id}\")\n",
    "\n",
    "    # Message to send.\n",
    "\n",
    "    with open(input_image, \"rb\") as f:\n",
    "        image = f.read()\n",
    "\n",
    "    message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": input_text\n",
    "            },\n",
    "            {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'jpeg',\n",
    "                        \"source\": {\n",
    "                            \"bytes\": image\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    messages = [message]\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
